{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Customer_Message_Domain_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y7T4PeJXDN8"
      },
      "source": [
        "# Problem Statement\n",
        "\n",
        "Haptik is one of the world's largest conversational AI platforms. It is a personal assistant mobile app, powered by a combination of artificial intelligence and human assistance. It has its domain in multiple fields including customer support, feedback, order status and live chat.\n",
        "\n",
        "We have with us the dataset of Haptik containing the messages it receives from the customers and which topic(class) the messages refer to.\n",
        "\n",
        "We need to create a model predicting which class a particular message belongs to using NLP.\n",
        "\n",
        "Additionally we use techniques like LSA (Latent Semantic Analysis) and LDA (Latent Dirichlet Allocation) to assign topics to new messages.\n",
        "\n",
        "\n",
        "# About the dataset\n",
        "\n",
        "The dataset consisted of `message` column along with the different column associated with the topic they could associated with it. \n",
        "\n",
        "We have combined the instances of different topic into a single column called cateogory.\n",
        "\n",
        "The dataset has details of 40000 messages You need to predict the category.\n",
        "\n",
        "For submission purposes, following is the label encoding of the category column:\n",
        "```python\n",
        "\n",
        "{0: 'casual',\n",
        " 1: 'food',\n",
        " 2: 'movies',\n",
        " 3: 'nearby',\n",
        " 4: 'other',\n",
        " 5: 'recharge',\n",
        " 6: 'reminders',\n",
        " 7: 'support',\n",
        " 8: 'travel'}\n",
        "```\n",
        "\n",
        "## Evaluation metrics\n",
        "\n",
        "For this particular dataset we are using simple `F1 score`(average=\"macro\") as the evaluation metric. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYRyGo7TQKep",
        "outputId": "718afabc-0b30-4ea3-d237-a90960508061"
      },
      "source": [
        "#Using Goole Colab : Mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7vDjnoaQaQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d14359-4774-4a21-a0f8-7319abe59bb9"
      },
      "source": [
        "#import modules\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "pd.set_option('display.max_columns',None)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import string\n",
        "import gensim\n",
        "from gensim.models.lsimodel import LsiModel\n",
        "from gensim import corpora\n",
        "from pprint import pprint\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUvCgQFzQkeg"
      },
      "source": [
        "# read the dataset and extract the test  and train data separately\n",
        "df_train=pd.read_csv('/content/drive/MyDrive/Customer_message_domain_classification/train_data.csv')\n",
        "df_test=pd.read_csv('/content/drive/MyDrive/Customer_message_domain_classification/test_data.csv')\n",
        "\n",
        "#Dropping df_train Id column : train_id\n",
        "train_id = df_train['MID']\n",
        "df_train.drop(['MID'], axis=1, inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uDby8BdsRJsu",
        "outputId": "36e36abe-61c0-4467-97bb-a85291f1c30e"
      },
      "source": [
        "#First look at data\n",
        "df_train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7am everyday</td>\n",
              "      <td>reminders</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>chocolate cake</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>closed mortice and tenon joint door dimentions</td>\n",
              "      <td>support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train eppo kelambum</td>\n",
              "      <td>travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yesterday i have cancelled the flight ticket</td>\n",
              "      <td>travel</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          message   category\n",
              "0                                    7am everyday  reminders\n",
              "1                                  chocolate cake       food\n",
              "2  closed mortice and tenon joint door dimentions    support\n",
              "3                             train eppo kelambum     travel\n",
              "4    yesterday i have cancelled the flight ticket     travel"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daNdHtRnRiQv",
        "outputId": "ca06c752-b66c-4cbf-d9fa-fa72e9db4e91"
      },
      "source": [
        "# Data shape and columns\n",
        "print(df_train.shape)\n",
        "print(df_train.columns)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40659, 2)\n",
            "Index(['message', 'category'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KQo9f1SRlmK",
        "outputId": "04320c87-0bfe-4b49-f34c-61ca671d8e4a"
      },
      "source": [
        "#Features Info\n",
        "df_train.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40659 entries, 0 to 40658\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   message   40659 non-null  object\n",
            " 1   category  40659 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 635.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "4RGfOsHyRo6t",
        "outputId": "dca0677b-84f8-47e2-8b7a-5063e3eb971e"
      },
      "source": [
        "# Describe data\n",
        "df_train.describe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>40659</td>\n",
              "      <td>40659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>39309</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>12/30/1899</td>\n",
              "      <td>travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>47</td>\n",
              "      <td>11063</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           message category\n",
              "count        40659    40659\n",
              "unique       39309        9\n",
              "top     12/30/1899   travel\n",
              "freq            47    11063"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z3I5ZbdXDOV"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZsrXbRcXDOW"
      },
      "source": [
        "In the Text Analytics, we convert the textual data into vectors so that we can apply machine learning algorithms to them.\n",
        "\n",
        "In this task we employ a normal TF-IDF vectorizer to vectorize the message column and label encode the category column, essentially making it a classification problem. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OYcgty6TknY"
      },
      "source": [
        "# Sampling only 1000 samples of each category\n",
        "df_train = df_train.groupby('category').apply(lambda x: x.sample(n=1000, random_state=0))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJikndhlXDOX"
      },
      "source": [
        "# Converting all messages to lower case and storing it\n",
        "all_text = df_train[\"message\"].str.lower()\n",
        "\n",
        "# Initialising TF-IDF object\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
        "\n",
        "# Vectorizing data\n",
        "tfidf.fit(all_text)\n",
        "\n",
        "# Storing the TF-IDF vectorized data into an array\n",
        "X = tfidf.transform(all_text).toarray()\n",
        "\n",
        "# Initiating a label encoder object\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Fitting the label encoder object on the data\n",
        "le.fit(df_train[\"category\"])\n",
        "\n",
        "# Transforming the data and storing it\n",
        "y = le.transform(df_train[\"category\"])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQeT_-kEXDOY"
      },
      "source": [
        "# Classification implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwYExNEEXDOa"
      },
      "source": [
        "In the previous tasks, we have cleaned the data and converted the textual data into numbers in order to enable us to apply machine learning models. \n",
        "\n",
        "In this task we apply Logistic Regression , Naive Bayes and Lienar SVM model onto the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmNl-8oPXDOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32fbae6-c844-4755-e032-94993746d8a5"
      },
      "source": [
        "#we split 70% of the data to training set while 30% of the data to validation \n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size=0.3, random_state=42) \n",
        "\n",
        "#X_train, X_valid shape\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6300, 7361)\n",
            "(2700, 7361)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9NcR0MfTwbx",
        "outputId": "331ffb60-a055-4ea7-dcd2-28685f2932f0"
      },
      "source": [
        "# Defining the Logistic Regression algorithm\n",
        "log_reg = LogisticRegression(random_state=0)\n",
        "log_reg.fit(X_train,y_train)\n",
        "\n",
        "# Predicting the values of validation data\n",
        "y_lr_pred = log_reg.predict(X_valid)\n",
        "print(\"Classification report - \\n\", classification_report(y_valid,y_lr_pred))\n",
        "\n",
        "#f1_score\n",
        "f1_score(y_valid,y_lr_pred, average='macro')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report - \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.80      0.58       300\n",
            "           1       0.73      0.50      0.59       326\n",
            "           2       0.89      0.78      0.83       287\n",
            "           3       0.65      0.65      0.65       288\n",
            "           4       0.67      0.71      0.69       296\n",
            "           5       0.77      0.77      0.77       298\n",
            "           6       0.89      0.82      0.85       314\n",
            "           7       0.76      0.67      0.72       297\n",
            "           8       0.80      0.66      0.72       294\n",
            "\n",
            "    accuracy                           0.71      2700\n",
            "   macro avg       0.74      0.71      0.71      2700\n",
            "weighted avg       0.74      0.71      0.71      2700\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7121925559391143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwbDbZk2UwPa",
        "outputId": "2ac9b820-0a67-4944-efef-57717db3f571"
      },
      "source": [
        "# Defining the Multinomial Naive Bayes algorithm\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train,y_train)\n",
        "\n",
        "# Predicting the values of validation data\n",
        "y_nb_pred = nb.predict(X_valid)\n",
        "print(\"Classification report - \\n\", classification_report(y_valid,y_nb_pred))\n",
        "\n",
        "#f1_score\n",
        "f1_score(y_valid,y_nb_pred, average='macro')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report - \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.62      0.58       300\n",
            "           1       0.81      0.51      0.63       326\n",
            "           2       0.71      0.83      0.76       287\n",
            "           3       0.66      0.65      0.66       288\n",
            "           4       0.75      0.69      0.72       296\n",
            "           5       0.68      0.85      0.75       298\n",
            "           6       0.80      0.87      0.83       314\n",
            "           7       0.74      0.69      0.72       297\n",
            "           8       0.78      0.71      0.74       294\n",
            "\n",
            "    accuracy                           0.71      2700\n",
            "   macro avg       0.72      0.71      0.71      2700\n",
            "weighted avg       0.72      0.71      0.71      2700\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7098202248522268"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDhhdDq4U8vi",
        "outputId": "6e3704fe-ed75-45bc-daf8-5c34becdcea1"
      },
      "source": [
        "# Defining the Linear Support vector algorithm\n",
        "lsvm = LinearSVC(random_state=0)\n",
        "lsvm.fit(X_train,y_train)\n",
        "\n",
        "# Predicting the values of validation data\n",
        "y_lsvm_pred = lsvm.predict(X_valid)\n",
        "print(\"Classification report - \\n\", classification_report(y_valid,y_lsvm_pred))\n",
        "\n",
        "#f1_score\n",
        "f1_score(y_valid,y_lsvm_pred, average='macro')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report - \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.76      0.59       300\n",
            "           1       0.73      0.53      0.61       326\n",
            "           2       0.88      0.84      0.86       287\n",
            "           3       0.63      0.66      0.64       288\n",
            "           4       0.74      0.70      0.72       296\n",
            "           5       0.75      0.78      0.76       298\n",
            "           6       0.86      0.83      0.84       314\n",
            "           7       0.72      0.66      0.69       297\n",
            "           8       0.80      0.67      0.73       294\n",
            "\n",
            "    accuracy                           0.71      2700\n",
            "   macro avg       0.73      0.71      0.72      2700\n",
            "weighted avg       0.73      0.71      0.72      2700\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7167828373922656"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw8liuy-XDOc"
      },
      "source": [
        "# Prediction on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9B4vvqgXDOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ccfa7f-1602-4377-abdf-e4c361466b22"
      },
      "source": [
        "# Prediction on test data\n",
        "\n",
        "#Test data shape and columns names\n",
        "print(df_test.shape)\n",
        "print(df_test.columns)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 1)\n",
            "Index(['message'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6DDKG0e-Wpi3",
        "outputId": "55e6d80d-fcb5-48cf-9f32-b95205dfc1f8"
      },
      "source": [
        "#First look at test data\n",
        "df_test.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nearest metro station</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pick up n drop service trough cab</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I wants to buy a bick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Show me pizza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the cheapest package to andaman and ni...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             message\n",
              "0                              Nearest metro station\n",
              "1                  Pick up n drop service trough cab\n",
              "2                              I wants to buy a bick\n",
              "3                                      Show me pizza\n",
              "4  What is the cheapest package to andaman and ni..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boNn42qIWtLi"
      },
      "source": [
        "#convert to lower case \n",
        "all_text = df_test[\"message\"].str.lower()\n",
        "\n",
        "# Transforming using the tfidf object - tfidf\n",
        "X_test = tfidf.transform(all_text).toarray()\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njloXPuDW4Q0"
      },
      "source": [
        "# Predicting using the linear svm model - lsvm\n",
        "y_test_pred = lsvm.predict(X_test)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_z44f2WXzZy",
        "outputId": "c3c40e81-e575-4562-cc96-c3e2e9b21f65"
      },
      "source": [
        "#Making df for submission\n",
        "subm=pd.DataFrame({\"category\": y_test_pred})\n",
        "print(subm.head())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   category\n",
            "0         3\n",
            "1         7\n",
            "2         4\n",
            "3         1\n",
            "4         8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6LcVSQqX32Q"
      },
      "source": [
        "# To CSV for submission\n",
        "subm.to_csv('category.csv',index=False)\n",
        "\n",
        "#from google.colab import files\n",
        "#files.download('category.csv')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg_EqM7mXDOg"
      },
      "source": [
        "# LSI Modeling\n",
        "In this task, we use LSI on the entire dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RJWxAZNXDOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b376e325-9532-4776-8d2b-f3b1c3bafb46"
      },
      "source": [
        "# Creating a stopwords list\n",
        "stop = set(stopwords.words('english'))\n",
        "exclude = set(string.punctuation)\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "# Function to lemmatize and remove the stopwords\n",
        "def clean(doc):\n",
        "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
        "    punc_free = \"\".join(ch for ch in stop_free if ch not in exclude)\n",
        "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
        "    return normalized\n",
        "\n",
        "# Creating a list of documents from the complaints column\n",
        "list_of_docs = df_train[\"message\"].tolist()\n",
        "\n",
        "# Implementing the function for all the complaints of list_of_docs\n",
        "doc_clean = [clean(doc).split() for doc in list_of_docs]\n",
        "\n",
        "# Code starts here\n",
        "dictionary = corpora.Dictionary(doc_clean)\n",
        "\n",
        "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
        "\n",
        "lsimodel = LsiModel(corpus=doc_term_matrix, num_topics=5, id2word=dictionary)\n",
        "\n",
        "pprint(lsimodel.print_topics())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '-0.347*\"reminder\" + -0.267*\"like\" + -0.267*\"cancel\" + -0.266*\"would\" + '\n",
            "  '-0.256*\"apiname\" + -0.256*\"exotel\" + -0.256*\"offset\" + -0.256*\"userid\" + '\n",
            "  '-0.255*\"taskname\" + -0.255*\"reminderlist\"'),\n",
            " (1,\n",
            "  '-0.831*\"want\" + -0.221*\"u\" + -0.187*\"know\" + -0.181*\"movie\" + -0.135*\"book\" '\n",
            "  '+ -0.128*\"ticket\" + -0.114*\"need\" + -0.108*\"hi\" + -0.096*\"please\" + '\n",
            "  '-0.092*\"service\"'),\n",
            " (2,\n",
            "  '-0.451*\"reminder\" + 0.328*\"call\" + 0.316*\"u\" + 0.233*\"wake\" + '\n",
            "  '-0.204*\"water\" + 0.197*\"march\" + 0.192*\"wakeup\" + -0.185*\"every\" + '\n",
            "  '-0.181*\"drink\" + -0.168*\"want\"'),\n",
            " (3,\n",
            "  '0.611*\"u\" + -0.419*\"want\" + 0.244*\"need\" + 0.238*\"reminder\" + '\n",
            "  '0.197*\"please\" + 0.143*\"movie\" + 0.118*\"service\" + -0.101*\"wake\" + '\n",
            "  '0.101*\"near\" + 0.101*\"help\"'),\n",
            " (4,\n",
            "  '-0.622*\"need\" + 0.510*\"u\" + -0.490*\"movie\" + -0.189*\"offer\" + 0.137*\"want\" '\n",
            "  '+ -0.115*\"ticket\" + -0.058*\"know\" + -0.052*\"today\" + 0.052*\"find\" + '\n",
            "  '-0.049*\"book\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKeWRQZRXDOi"
      },
      "source": [
        "# LDA Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw20NOaIXDOj"
      },
      "source": [
        "Topic modeling using LDA. \n",
        "\n",
        "We found the optimum no. of topics using coherence score and then create a model attaining to the optimum no. of topics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KboYB3mXDOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df296ed-6788-4dc7-a0a4-b587b6678ab0"
      },
      "source": [
        "# doc_term_matrix - Word matrix created in the last task\n",
        "# dictionary - Dictionary created in the last task\n",
        "\n",
        "# Function to calculate coherence values\n",
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    topic_list : No. of topics chosen\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    topic_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.ldamodel.LdaModel(doc_term_matrix, random_state = 0, num_topics=num_topics, id2word = dictionary, iterations=10)\n",
        "        topic_list.append(num_topics)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return topic_list, coherence_values\n",
        "\n",
        "# Calling the function\n",
        "topic_list, coherence_value_list = compute_coherence_values(dictionary=dictionary, corpus=doc_term_matrix, texts=doc_clean, start=1, limit=41, step=5)\n",
        "print(coherence_value_list)\n",
        "\n",
        "# Finding the index associated with maximum coherence value\n",
        "max_index=coherence_value_list.index(max(coherence_value_list))\n",
        "\n",
        "# Finding the optimum no. of topics associated with the maximum coherence value\n",
        "opt_topic= topic_list[max_index]\n",
        "print(\"Optimum no. of topics:\", opt_topic)\n",
        "\n",
        "# Implementing LDA with the optimum no. of topic\n",
        "lda_model = LdaModel(corpus=doc_term_matrix, num_topics=opt_topic, id2word = dictionary, iterations=10, passes = 30,random_state=0)\n",
        "\n",
        "# display top 5 topics\n",
        "pprint(lda_model.print_topic(5))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.3287476298674388, 0.4801812391625579, 0.5306698259321219, 0.5376618801954907, 0.5587078765648961, 0.572049572781549, 0.5663902769474314, 0.5889600955365673]\n",
            "Optimum no. of topics: 36\n",
            "('0.064*\"800\" + 0.047*\"medicine\" + 0.040*\"day\" + 0.037*\"got\" + 0.020*\"trip\" + '\n",
            " '0.015*\"many\" + 0.014*\"theater\" + 0.012*\"moto\" + 0.011*\"showing\" + '\n",
            " '0.010*\"low\"')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}